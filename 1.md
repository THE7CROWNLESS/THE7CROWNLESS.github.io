# DNN code(pytorch)

### pytorch神经网络模板

这是一个基于pytorch框架的神经网络模板，可以用于各种类型的深度学习任务。以下是模板的主要代码结构：

```
import torch
import torch.nn as nn
import torch.optim as optim

class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        # 定义神经网络结构
        self.layer1 = nn.Linear(input_size, hidden_size)
        self.layer2 = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        # 定义前向传播过程
        x = self.layer1(x)
        x = torch.relu(x)
        x = self.layer2(x)
        output = torch.sigmoid(x)
        return output

# 定义超参数
learning_rate = 0.01
num_epochs = 1000

# 初始化神经网络
neural_network = NeuralNetwork()

# 定义损失函数和优化器
criterion = nn.BCELoss()
optimizer = optim.SGD(neural_network.parameters(), lr=learning_rate)

# 训练神经网络
for epoch in range(num_epochs):
    # 前向传播
    outputs = neural_network(inputs)
    loss = criterion(outputs, labels)

    # 反向传播和优化
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # 打印损失值
    if (epoch+1) % 100 == 0:
        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))

```

### 以下是一些常见的数据处理方法：

- 标准化（Normalization）：对数据进行缩放，使其均值为0，方差为1，常用于神经网络的训练。
- One-hot编码（One-Hot Encoding）：将离散型变量转换为伪连续变量，常用于分类问题。pd.get_dummies(dataframe, dummy = True)
- 缺失值处理（Missing Value Imputation）：填补缺失的数据，常用的方法有均值、中位数和众数等。
- 数据降维（Dimensionality Reduction）：将高维数据转化为低维数据，常用的方法有主成分分析（PCA）和线性判别分析（LDA）等。

```jsx
inplace = True
pd.concat()
number归一化:dataframe.apply(lambda),dim = 0
str-->onehot:pd.get_dummies()
dataframe.fillna()
torch.cat()
```

### 以下是`torchvision`中`transforms`模块中的一些常用接口方法：

- `ToTensor()`：将PIL图片或numpy.ndarray数组转换为torch.Tensor，同时将数据缩放到[0,1]之间。
- `Normalize(mean, std)`：标准化数据，使得数据的均值为`mean`，方差为`std`。
- `RandomCrop(size, padding=None, pad_if_needed=False, fill=0, padding_mode='constant')`：随机裁剪图片的一部分，输出图片大小为`size`。
- `RandomHorizontalFlip(p=0.5)`：有50%的概率对图片进行水平翻转。
- `RandomVerticalFlip(p=0.5)`：有50%的概率对图片进行垂直翻转。
- `RandomRotation(degrees, resample=False, expand=False, center=None)`：对图片进行随机旋转，旋转角度在`[-degrees, degrees]`之间。
- `ColorJitter(brightness=0, contrast=0, saturation=0, hue=0)`：随机改变图片的亮度、对比度、饱和度和色调。
- `Resize(size, interpolation=<InterpolationMode.BILINEAR: 2>)`：将图片缩放到指定大小。

你可以根据需要选择其中的接口方法，并将其应用到数据集中，以实现数据增强的目的。

```
from torchvision import transforms

# 定义transform
transform = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 对数据集应用transform
trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)

```

对抗样本（Adversarial Examples）是指对原始数据进行微小的扰动，从而导致神经网络的输出结果发生错误的样本。对抗样本可以用于测试神经网络的鲁棒性，并且也可以被用于攻击神经网络。常见的对抗样本生成方法包括Fast Gradient Sign Method（FGSM）、Projected Gradient Descent（PGD）等。可以使用pytorch框架中的`torchattacks`库来生成对抗样本。